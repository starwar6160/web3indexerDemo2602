# ç”Ÿäº§çº§ç´¢å¼•å™¨ä¿®å¤æ–¹æ¡ˆ

**æ—¥æœŸ**: 2026-02-06
**ä¼˜å…ˆçº§**: ğŸ”´ CRITICAL - å¿…é¡»ä¿®å¤æ‰èƒ½æŠ•å…¥ç”Ÿäº§
**è¯Šæ–­è€…**: Claude + ä¸“å®¶å®¡è®¡

---

## æ‰§è¡Œæ‘˜è¦

å½“å‰ç´¢å¼•å™¨å­˜åœ¨ **3 ä¸ªè‡´å‘½é—®é¢˜** ä¼šå¯¼è‡´æ•°æ®æŸåå’Œæ°¸ä¹…æ€§ä¸¢å—ï¼š

1. **ä¼šæ¼å—ä¸”æ— æ³•è‡ªæ„ˆ** - åŸºäº `max(number)` çš„è¿›åº¦æ£€æŸ¥æ— æ³•å‘ç°ç¼ºå£
2. **å†™å…¥ä¸å¹‚ç­‰** - é‡å¯/å¹¶å‘ä¼šå› å”¯ä¸€çº¦æŸå†²çªå¯¼è‡´æ•´ä¸ªæ‰¹æ¬¡å¤±è´¥
3. **Reorg å¤„ç†é€»è¾‘æ ¹æœ¬æ€§ç¼ºé™·** - æ— æ³•å¯é æ£€æµ‹å’Œå¤„ç†é“¾é‡ç»„

**é£é™©ç­‰çº§**: ğŸ”´ **æé«˜** - ä¼šå¯¼è‡´æ•°æ®æ°¸ä¹…æŸåï¼Œä¸‹æ¸¸åº”ç”¨ä¼šå‡ºç°æ•°æ®æ–­å±‚

---

## é—®é¢˜ 1: æ°¸ä¹…æ€§æ¼å—ï¼ˆCriticalï¼‰

### ç—‡çŠ¶
```
æ•°æ®åº“é‡Œæœ‰å— 1000-1100ï¼Œä½†ä¸­é—´ç¼ºäº† 1050-1059
ä¸‹ä¸€æ¬¡é‡å¯ä» 1101 å¼€å§‹ï¼Œæ°¸è¿œä¸ä¼šå†è¡¥ 1050-1059
```

### æ ¹æœ¬åŸå› 
`index-production.ts:324` ä½¿ç”¨ `getMaxBlockNumber()` ä½œä¸ºåŒæ­¥èµ·ç‚¹ï¼š

```typescript
// âŒ é”™è¯¯ï¼šåªçœ‹æœ€å¤§å€¼ï¼Œä¸ç®¡ä¸­é—´ç¼ºå£
const localMaxBlock = await blockRepository.getMaxBlockNumber();
let startBlock = localMaxBlock ? localMaxBlock + 1n : 0n;
```

**åœºæ™¯**ï¼š
1. æ‰¹é‡æŠ“å– `1000-1019`ï¼Œå…¶ä¸­ `1005` çš„ RPC è°ƒç”¨å¤±è´¥ï¼ˆç½‘ç»œæŠ–åŠ¨/429ï¼‰
2. å½“å‰ä»£ç ï¼šè®°å½• `1005` å¤±è´¥ï¼Œç»§ç»­æŠ“ `1006-1019`
3. å†™å…¥ `1000-1004` å’Œ `1006-1019`
4. æ•°æ®åº“ `max(number) = 1019`
5. **ç¼ºå£ `1005` æ°¸ä¹…ä¸¢å¤±**ï¼ˆä¸‹æ¬¡ä» `1020` å¼€å§‹ï¼‰

### ä¿®å¤æ–¹æ¡ˆ Aï¼šæŒä¹…åŒ– Checkpointï¼ˆæ¨èï¼‰

#### æ•°æ®åº“ Schema

```sql
CREATE TABLE sync_status (
  chain_id bigint NOT NULL DEFAULT 1,
  next_block bigint NOT NULL,
  confirmed_block bigint NOT NULL,
  head_block bigint NOT NULL,
  updated_at timestamptz NOT NULL DEFAULT now(),
  PRIMARY KEY (chain_id)
);

CREATE TABLE sync_gaps (
  chain_id bigint NOT NULL,
  gap_start bigint NOT NULL,
  gap_end bigint NOT NULL,
  detected_at timestamptz NOT NULL DEFAULT now(),
  retry_count integer NOT NULL DEFAULT 0,
  status varchar(20) NOT NULL DEFAULT 'pending', -- pending, retrying, filled
  PRIMARY KEY (chain_id, gap_start, gap_end)
);

CREATE INDEX idx_sync_gaps_status ON sync_gaps(chain_id, status);
```

#### å®ç°ä»£ç 

```typescript
// database/sync-status-repository.ts
export class SyncStatusRepository {
  async getSyncStatus(chainId: bigint = 1n): Promise<SyncStatus | null> {
    const result = await this.db
      .selectFrom('sync_status')
      .selectAll()
      .where('chain_id', '=', chainId)
      .executeTakeFirst();

    return result || null;
  }

  /**
   * ä¸¥æ ¼è¿ç»­å†™å…¥ï¼šåªæœ‰è¿ç»­åŒºé—´æˆåŠŸæ‰æ¨è¿› next_block
   */
  async advanceNextBlock(
    chainId: bigint,
    fromBlock: bigint,
    toBlock: bigint
  ): Promise<void> {
    await this.db
      .updateTable('sync_status')
      .set({
        next_block: toBlock + 1n,
        updated_at: new Date().toISOString(),
      })
      .where('chain_id', '=', chainId)
      .where('next_block', '=', fromBlock) // CAS æ“ä½œ
      .execute();
  }

  /**
   * æ£€æµ‹ç¼ºå£
   */
  async detectGaps(chainId: bigint = 1n): Promise<Gap[]> {
    const result = await this.db
      .selectFrom('blocks')
      .select(sql`number + 1`.as('gap_start'))
      .select(sql`
        (SELECT MIN(number) - 1 FROM blocks b2 WHERE b2.number > blocks.number)
      `.as('gap_end'))
      .where(sql`
        NOT EXISTS (
          SELECT 1 FROM blocks b2 WHERE b2.number = blocks.number + 1
        )
        AND number < (SELECT MAX(number) FROM blocks)
      `.as('exists'))
      .execute();

    return result.filter(row => row.gap_end !== null);
  }

  async reportGap(
    chainId: bigint,
    gapStart: bigint,
    gapEnd: bigint
  ): Promise<void> {
    await this.db
      .insertInto('sync_gaps')
      .values({
        chain_id: chainId,
        gap_start: gapStart,
        gap_end: gapEnd,
      })
      .onConflict((oc) => oc.doNothing())
      .execute();
  }
}
```

#### ä¿®æ”¹åŒæ­¥é€»è¾‘

```typescript
// index-production.ts
async function syncBlockBatch(
  startBlock: bigint,
  endBlock: bigint
): Promise<void> {
  const syncRepo = new SyncStatusRepository();
  const status = await syncRepo.getSyncStatus();

  // âŒ åˆ é™¤æ—§é€»è¾‘ï¼šä» max+1 å¼€å§‹
  // const localMaxBlock = await blockRepository.getMaxBlockNumber();

  // âœ… æ–°é€»è¾‘ï¼šä» checkpoint å¼€å§‹
  const nextBlock = status?.next_block || 0n;

  // ä¸¥æ ¼éªŒè¯è¿ç»­æ€§
  if (startBlock !== nextBlock) {
    throw new Error(
      `Non-sequential sync: startBlock=${startBlock}, expected nextBlock=${nextBlock}`
    );
  }

  const rawBlocks: unknown[] = [];
  let blockNumber = startBlock;
  let hasFailures = false;

  // ä»»ä½•å—å¤±è´¥å¿…é¡»é‡è¯•ï¼Œä¸èƒ½è·³è¿‡
  while (blockNumber <= endBlock) {
    try {
      const block = await rpcCallWithMetrics(
        `getBlock-${blockNumber}`,
        () => client.getBlock({ blockNumber })
      );
      rawBlocks.push(block);
      blockNumber = blockNumber + 1n;
    } catch (error) {
      logger.error({ error, blockNumber: blockNumber.toString() }, 'Failed to fetch block');

      // è®°å½•ç¼ºå£
      await syncRepo.reportGap(1n, blockNumber, endBlock);
      hasFailures = true;
      break; // åœæ­¢æ‰¹æ¬¡ï¼Œä¸è¦è·³è¿‡å¤±è´¥çš„å—
    }
  }

  if (hasFailures) {
    throw new Error(`Batch failed at block ${blockNumber}, will retry`);
  }

  // å†™å…¥æ•°æ®åº“
  const savedCount = await blockRepository.saveValidatedBlocks(rawBlocks);

  // âœ… åªæœ‰å…¨éƒ¨æˆåŠŸæ‰æ¨è¿› checkpoint
  if (savedCount === rawBlocks.length) {
    await syncRepo.advanceNextBlock(1n, startBlock, endBlock);
  }
}
```

### ä¿®å¤æ–¹æ¡ˆ Bï¼šå®šæœŸ Gap Detectionï¼ˆè¾…åŠ©ï¼‰

```typescript
// utils/gap-detector.ts
export async function detectAndFillGaps(): Promise<void> {
  const syncRepo = new SyncStatusRepository();
  const gaps = await syncRepo.detectGaps(1n);

  if (gaps.length === 0) {
    logger.info('No gaps detected');
    return;
  }

  logger.warn({ gapCount: gaps.length }, 'Gaps detected, attempting to fill');

  for (const gap of gaps) {
    try {
      await syncBlockBatch(gap.gap_start, gap.gap_end);
      logger.info(
        { gapStart: gap.gap_start.toString(), gapEnd: gap.gap_end.toString() },
        'Gap filled successfully'
      );
    } catch (error) {
      logger.error({ error, gap }, 'Failed to fill gap');
      // æ ‡è®°ä¸ºå¾…é‡è¯•
      await syncRepo.updateGapStatus(gap, 'pending');
    }
  }
}

// åœ¨ä¸»å¾ªç¯ä¸­å®šæœŸè¿è¡Œ
setInterval(() => {
  detectAndFillGaps().catch((error) => {
    logger.error({ error }, 'Gap detection failed');
  });
}, 60_000); // æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
```

---

## é—®é¢˜ 2: å†™å…¥ä¸å¹‚ç­‰ï¼ˆCriticalï¼‰

### ç—‡çŠ¶
```
é‡å¯åå°è¯•å†™å…¥å— 3200ï¼ˆå·²å­˜åœ¨ï¼‰
â†’ UNIQUE çº¦æŸå†²çª
â†’ æ•´ä¸ªäº‹åŠ¡å›æ»š
â†’ 3200-3299 å…¨éƒ¨å†™ä¸è¿›å»
â†’ ç´¢å¼•å™¨å¡æ­»
```

### æ ¹æœ¬åŸå› 
`block-repository.ts:67` ä½¿ç”¨çº¯ `INSERT`ï¼š

```typescript
// âŒ é”™è¯¯ï¼šæ²¡æœ‰å†²çªå¤„ç†
await trx
  .insertInto('blocks')
  .values(dbBlocks)
  .returningAll()
  .execute();
```

**åœºæ™¯**ï¼š
1. æ­£å¸¸å†™å…¥ `3200-3299`
2. ç´¢å¼•å™¨å´©æºƒ/é‡å¯
3. ä» checkpoint é‡æ–°å°è¯•å†™å…¥ `3200-3299`
4. PostgreSQL æŠ›å‡º `duplicate key value violates unique constraint "blocks_pkey"`
5. **æ•´ä¸ªæ‰¹æ¬¡å›æ»šï¼Œç´¢å¼•å™¨åœæ»**

### ä¿®å¤æ–¹æ¡ˆï¼šUpsert è¯­ä¹‰

#### æ•°æ®åº“ Schema è°ƒæ•´

```sql
-- âŒ åˆ é™¤æ—§ä¸»é”®
-- ALTER TABLE blocks DROP CONSTRAINT blocks_pkey;

-- âœ… æ–°ä¸»é”®ï¼šæ”¯æŒå¤šé“¾ + å†²çªå¤„ç†
ALTER TABLE blocks ADD COLUMN IF NOT EXISTS chain_id bigint NOT NULL DEFAULT 1;
ALTER TABLE blocks ADD CONSTRAINT blocks_pkey PRIMARY KEY (chain_id, number);

-- âœ… ä¿ç•™ hash å”¯ä¸€çº¦æŸï¼ˆç”¨äº reorg æ£€æµ‹ï¼‰
ALTER TABLE blocks DROP CONSTRAINT IF EXISTS blocks_hash_key;
ALTER TABLE blocks ADD CONSTRAINT blocks_hash_key UNIQUE (chain_id, hash);
```

#### å®ç° Upsert

```typescript
// database/block-repository.ts
async saveValidatedBlocks(rawBlocks: unknown[]): Promise<number> {
  if (rawBlocks.length === 0) return 0;

  const validatedBlocks = validateBlocks(rawBlocks);
  if (validatedBlocks.length === 0) return 0;

  const dbBlocks = validatedBlocks.map(toDbBlock);

  const saved = await this.db.transaction().execute(async (trx) => {
    const results: Block[] = [];

    for (const block of dbBlocks) {
      // âœ… ä½¿ç”¨ ON CONFLICT DO UPDATE
      const result = await trx
        .insertInto('blocks')
        .values(block)
        .returningAll()
        .onConflict((oc) => oc
          .column(['chain_id', 'number'])
          .doUpdateSet({
            // æ›´æ–°æ‰€æœ‰å¯èƒ½å˜åŒ–çš„å­—æ®µ
            hash: sql`excluded.hash`,
            parent_hash: sql`excluded.parent_hash`,
            timestamp: sql`excluded.timestamp`,
            updated_at: new Date().toISOString(),
          })
          .where(({ eb, or }) => or([
            eb('blocks.hash', '!=', sql`${block.hash}`), // åªæœ‰ hash ä¸åŒæ‰æ›´æ–°
            eb('blocks.parent_hash', '!=', sql`${block.parent_hash}`),
          ]))
        )
        .executeTakeFirst();

      if (result) {
        results.push(result);
      }
    }

    return results;
  });

  console.log(`[Repository] âœ… Saved ${saved.length}/${rawBlocks.length} blocks`);

  return saved.length;
}
```

#### Upsert è¯­ä¹‰è¯´æ˜

**è¡Œä¸º**ï¼š
- **æ–°å—**ï¼šæ’å…¥
- **å·²å­˜åœ¨ä¸” hash ç›¸åŒ**ï¼šè·³è¿‡ï¼ˆå¹‚ç­‰ï¼‰
- **å·²å­˜åœ¨ä½† hash ä¸åŒ**ï¼šæ›´æ–°ï¼ˆreorg åœºæ™¯ï¼‰

**Reorg æ£€æµ‹**ï¼š
```typescript
if (updatedCount > 0 && oldHash !== newHash) {
  // è§¦å‘ reorg è­¦æŠ¥
  logger.warn(
    { blockNumber, oldHash, newHash },
    'Block hash changed - possible reorg'
  );
  await handleReorg(blockRepository, blockNumber - 1n);
}
```

---

## é—®é¢˜ 3: Reorg å¤„ç†é€»è¾‘ç¼ºé™·ï¼ˆCriticalï¼‰

### ç—‡çŠ¶
```
é“¾åœ¨é«˜åº¦ 5000 å‘ç”Ÿ reorg
å½“å‰ä»£ç ï¼š
  - è¦ä¹ˆå®Œå…¨æ£€æµ‹ä¸åˆ°ï¼ˆsilent wrongï¼‰
  - è¦ä¹ˆå›æ»šåˆ°é”™è¯¯é«˜åº¦ï¼ˆè¿‡æµ…/è¿‡æ·±ï¼‰
åç»­æ‰€æœ‰æ•°æ®éƒ½åœ¨é”™è¯¯é“¾ä¸Š
```

### æ ¹æœ¬åŸå› 

#### é—®é¢˜ 3.1ï¼šæ•°æ®æ¨¡å‹ä¸æ”¯æŒåˆ†å‰

```sql
-- âŒ å½“å‰ schemaï¼šæ¯ä¸ªé«˜åº¦åªèƒ½æœ‰ä¸€ä¸ª hash
CREATE TABLE blocks (
  number bigint PRIMARY KEY,
  hash varchar(66) UNIQUE,
  ...
);
```

**é—®é¢˜**ï¼šæ— æ³•å­˜å‚¨åŒé«˜åº¦çš„å¤šä¸ªåˆ†å‰å—

#### é—®é¢˜ 3.2ï¼šReorg æ£€æµ‹é€»è¾‘é”™è¯¯

`reorg-handler.ts:38` çš„ `detectReorg()`ï¼š

```typescript
// âŒ é”™è¯¯ï¼šexpectedParentHash æ˜¯ä¸Šè½®çš„ block.parentHash
// è¯­ä¹‰ä¸ç­‰äº"æˆ‘æœŸæœ›çš„æ–°å—çš„çˆ¶ hash"
const expectedParent = await blockRepository.findByHash(expectedParentHash);
```

**åœºæ™¯**ï¼š
1. æ‰¹é‡æŠ“ `3200-3299`ï¼Œä¼ å…¥ `parentHash = 3199.parentHash`
2. ä½† `3200.parentHash` å¯èƒ½æŒ‡å‘å¦ä¸€ä¸ªåˆ†å‰
3. **æ£€æµ‹å¤±æ•ˆ**

#### é—®é¢˜ 3.3ï¼šfindCommonAncestor æ— æ³•å·¥ä½œ

`reorg-handler.ts:124`ï¼š

```typescript
// âŒ é”™è¯¯ï¼šå°è¯•æ²¿"æ–°é“¾"å‘ä¸Šèµ°
// ä½†æ•°æ®åº“é‡Œåªæœ‰"æ—§é“¾"çš„æ•°æ®
const newBlock = await blockRepository.findByHash(currentHash);
if (!newBlock) {
  // æ–°é“¾çš„å—ä¸åœ¨åº“é‡Œï¼Œæ— æ³•å‘ä¸Šè¿½æº¯
  break; // æ‰¾ä¸åˆ°å…±åŒç¥–å…ˆ
}
```

### ä¿®å¤æ–¹æ¡ˆ Aï¼šConfirmation Depthï¼ˆæ¨èï¼‰

#### æ ¸å¿ƒæ€æƒ³

**åªç¡®è®¤"å®‰å…¨åŒº"çš„å—ï¼Œreorg å‘ç”Ÿåœ¨ pending åŒºä¸å½±å“å·²ç¡®è®¤æ•°æ®**

```
å®‰å…¨åŒºï¼ˆfinalizedï¼‰:   0 ----> head - confirmations
Pending åŒºï¼ˆä¸´æ—¶ï¼‰:    head - confirmations ----> head
```

#### æ•°æ®åº“ Schema

```sql
-- ä¸»è¡¨ï¼šåªå­˜å·²ç¡®è®¤çš„å—
CREATE TABLE blocks (
  chain_id bigint NOT NULL,
  number bigint NOT NULL,
  hash varchar(66) NOT NULL,
  parent_hash varchar(66) NOT NULL,
  timestamp bigint NOT NULL,
  finalized boolean NOT NULL DEFAULT true,
  created_at timestamptz NOT NULL DEFAULT now(),
  PRIMARY KEY (chain_id, number),
  UNIQUE (chain_id, hash)
);

-- ä¸´æ—¶è¡¨ï¼šå­˜ pending åŒºçš„å—ï¼ˆå¯é€‰ï¼Œä¹Ÿå¯ä»¥åœ¨å†…å­˜ï¼‰
CREATE TABLE blocks_pending (
  chain_id bigint NOT NULL,
  number bigint NOT NULL,
  hash varchar(66) NOT NULL,
  parent_hash varchar(66) NOT NULL,
  timestamp bigint NOT NULL,
  received_at timestamptz NOT NULL DEFAULT now(),
  PRIMARY KEY (chain_id, number, hash)
);

CREATE INDEX idx_blocks_pending_chain_number ON blocks_pending(chain_id, number);
```

#### å®ç° Confirmation Depth

```typescript
// utils/confirmation-depth.ts
const CONFIRMATION_DEPTH = 12; // ä»¥å¤ªåŠä¸»ç½‘çº¦ 2 åˆ†é’Ÿ
const ANVIL_CONFIRMATION_DEPTH = 2; // Anvil æµ‹è¯•ç½‘ 4 ç§’

export async function syncWithConfirmationDepth(): Promise<void> {
  const chainId = 1n;
  const confirmationDepth = isAnvil ? ANVIL_CONFIRMATION_DEPTH : CONFIRMATION_DEPTH;

  while (isRunning) {
    const headBlock = await rpcCallWithMetrics(
      'getBlockNumber',
      () => client.getBlockNumber()
    );

    const safeBlock = headBlock - BigInt(confirmationDepth);

    // 1. è·å– pending åŒºçš„æœ€æ–°çŠ¶æ€
    const localMax = await blockRepository.getMaxBlockNumber();
    const pendingStart = localMax ? localMax + 1n : 0n;

    // 2. æŠ“å– pending åŒºï¼ˆå…è®¸é‡è¯•ã€å…è®¸è¦†ç›–ï¼‰
    if (pendingStart <= headBlock) {
      await syncPendingBlocks(pendingStart, headBlock);
    }

    // 3. ç¡®è®¤å®‰å…¨åŒº
    if (safeBlock > localMax) {
      await confirmBlocks(safeBlock);
    }

    await sleep(Number(config.POLL_INTERVAL_MS));
  }
}

async function syncPendingBlocks(
  startBlock: bigint,
  endBlock: bigint
): Promise<void> {
  // å­˜å…¥ blocks_pendingï¼ˆå…è®¸é‡å¤åˆå¹¶ï¼Œä¸´æ—¶æ•°æ®ï¼‰
  for (let num = startBlock; num <= endBlock; num++) {
    try {
      const block = await client.getBlock({ blockNumber: num });

      await db
        .insertInto('blocks_pending')
        .values({
          chain_id: 1n,
          number: block.number,
          hash: block.hash,
          parent_hash: block.parentHash,
          timestamp: block.timestamp,
        })
        .onConflict((oc) => oc
          .column(['chain_id', 'number', 'hash'])
          .doUpdateSet({ received_at: new Date().toISOString() })
        )
        .execute();
    } catch (error) {
      // Pending åŒºå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œä¸‹æ¬¡é‡è¯•
      logger.warn({ error, blockNumber: num.toString() }, 'Failed to fetch pending block');
    }
  }
}

async function confirmBlocks(safeBlock: bigint): Promise<void> {
  // ä» pending åŒºé€‰æ‹© canonical é“¾è¿ç§»åˆ° blocks è¡¨
  const result = await db
    .selectFrom('blocks_pending')
    .selectAll()
    .where('number', '<=', safeBlock)
    .orderBy('number', 'asc')
    .execute();

  const chain = buildCanonicalChain(result); // æŒ‰ parent_hash é“¾æ¥

  for (const block of chain) {
    await blockRepository.saveValidatedBlocks([block]);
  }

  // æ¸…ç†å·²ç¡®è®¤çš„ pending æ•°æ®
  await db
    .deleteFrom('blocks_pending')
    .where('number', '<=', safeBlock)
    .execute();
}

function buildCanonicalChain(pendingBlocks: PendingBlock[]): PendingBlock[] {
  // ä» genesis å¼€å§‹æŒ‰ parent_hash é“¾æ¥
  const chainMap = new Map<bigint, PendingBlock>();
  for (const block of pendingBlocks) {
    chainMap.set(block.number, block);
  }

  const canonical: PendingBlock[] = [];
  let currentNumber = 0n; // å‡è®¾ä» 0 å¼€å§‹

  while (true) {
    const block = chainMap.get(currentNumber);
    if (!block) break;

    canonical.push(block);
    currentNumber = block.number + 1n;
  }

  return canonical;
}
```

#### Reorg æ£€æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼‰

```typescript
// åœ¨ç¡®è®¤æ—¶æ£€æµ‹ reorg
async function confirmBlocks(safeBlock: bigint): Promise<void> {
  const currentHead = await blockRepository.getMaxBlockNumber();
  const currentBlock = await blockRepository.findById(currentHead!);

  const pendingBlock = await db
    .selectFrom('blocks_pending')
    .where('number', '=', currentHead! + 1n)
    .orderBy('received_at', 'desc')
    .limit(1)
    .executeTakeFirst();

  if (pendingBlock && pendingBlock.parent_hash !== currentBlock!.hash) {
    // Reorg å‘ç”Ÿï¼
    logger.warn(
      {
        blockNumber: (currentHead! + 1n).toString(),
        oldParent: currentBlock!.hash,
        newParent: pendingBlock.parent_hash,
      },
      'Reorg detected in pending zone'
    );

    // å›æ»šåˆ°å…±åŒç¥–å…ˆ
    const commonAncestor = await findCommonAncestorInPending(
      currentBlock!.hash,
      pendingBlock.parent_hash
    );

    await blockRepository.deleteBlocksAfter(commonAncestor);
  }

  // ç»§ç»­æ­£å¸¸ç¡®è®¤æµç¨‹...
}
```

**ä¼˜åŠ¿**ï¼š
- âœ… Reorg åªå‘ç”Ÿåœ¨ pending åŒºï¼Œä¸å½±å“å·²ç¡®è®¤æ•°æ®
- âœ… é€»è¾‘ç®€å•ï¼Œæ— éœ€å¤æ‚çš„åˆ†å‰ç®¡ç†
- âœ… ç¬¦åˆåŒºå—é“¾æœ€ä½³å®è·µï¼ˆç±»ä¼¼ Etherscan's confirmation countï¼‰

**åŠ£åŠ¿**ï¼š
- âš ï¸ æ•°æ®æœ‰ 2-12 åˆ†é’Ÿå»¶è¿Ÿï¼ˆå–å†³äºé“¾çš„ç¡®è®¤æ·±åº¦ï¼‰

---

## ä¿®å¤æ–¹æ¡ˆ Bï¼šCanonical æ ‡è®°ï¼ˆå¤æ‚ä½†å®æ—¶ï¼‰

å¦‚æœéœ€è¦å®æ—¶æ•°æ®ï¼ˆ0 å»¶è¿Ÿï¼‰ï¼Œä½¿ç”¨ canonical æ ‡è®°æ¨¡å‹ï¼š

```sql
CREATE TABLE blocks (
  chain_id bigint NOT NULL,
  number bigint NOT NULL,
  hash varchar(66) NOT NULL,
  parent_hash varchar(66) NOT NULL,
  timestamp bigint NOT NULL,
  canonical boolean NOT NULL DEFAULT true, -- æ˜¯å¦ä¸ºä¸»é“¾
  created_at timestamptz NOT NULL DEFAULT now(),
  PRIMARY KEY (chain_id, number, hash), -- å…è®¸åŒé«˜åº¦å¤š hash
  INDEX (chain_id, number, canonical)    -- å¿«é€ŸæŸ¥è¯¢ä¸»é“¾
);

CREATE UNIQUE INDEX idx_blocks_canonical ON blocks(chain_id, number)
WHERE canonical = true; -- æ¯ä¸ª height æœ€å¤šä¸€ä¸ª canonical
```

**Reorg å¤„ç†**ï¼š

```typescript
async function handleReorg(newBlockHash: string, newBlockNumber: bigint): Promise<void> {
  await db.transaction().execute(async (trx) => {
    // 1. æŠŠæ—§ canonical é“¾æ ‡è®°ä¸º non-canonical
    await trx
      .updateTable('blocks')
      .set({ canonical: false })
      .where('number', '>=', newBlockNumber)
      .where('canonical', '=', true)
      .execute();

    // 2. æŠŠæ–°é“¾æ ‡è®°ä¸º canonical
    const newBlocks = await fetchChain(newBlockHash);
    for (const block of newBlocks) {
      await trx
        .insertInto('blocks')
        .values({ ...block, canonical: true })
        .onConflict((oc) => oc
          .column(['chain_id', 'number', 'hash'])
          .doUpdateSet({ canonical: true })
        )
        .execute();
    }
  });
}
```

**æŸ¥è¯¢æ—¶**ï¼š

```sql
-- åªæŸ¥è¯¢ä¸»é“¾
SELECT * FROM blocks WHERE canonical = true ORDER BY number;
```

---

## å®æ–½ä¼˜å…ˆçº§

### Phase 1: ç´§æ€¥ä¿®å¤ï¼ˆ1-2 å¤©ï¼‰

1. âœ… **æ·»åŠ  `sync_status` è¡¨** - é˜²æ­¢æ¼å—
2. âœ… **å®ç° Upsert** - é˜²æ­¢é‡å¯å¡æ­»
3. âœ… **Gap Detection** - å®šæœŸæ£€æŸ¥å¹¶è¡¥æ´

### Phase 2: Reorg ä¿®å¤ï¼ˆ3-5 å¤©ï¼‰

4. âœ… **é€‰æ‹© Reorg æ–¹æ¡ˆ**ï¼ˆæ¨è Confirmation Depthï¼‰
5. âœ… **è°ƒæ•´ Schema**ï¼ˆåŠ  `chain_id`, `finalized`, `blocks_pending`ï¼‰
6. âœ… **é‡æ„åŒæ­¥é€»è¾‘**ï¼ˆpending + confirm ä¸¤é˜¶æ®µï¼‰
7. âœ… **æµ‹è¯• Reorg åœºæ™¯**

### Phase 3: å¢å¼ºåŠŸèƒ½ï¼ˆ1 å‘¨ï¼‰

8. âš ï¸ **æ·»åŠ  `chain_id` æ”¯æŒ**ï¼ˆå¤šé“¾ç´¢å¼•ï¼‰
9. âš ï¸ **å®Œå–„ç›‘æ§å‘Šè­¦**ï¼ˆgap æ£€æµ‹ã€reorg å‘Šè­¦ï¼‰
10. âš ï¸ **æ·»åŠ é›†æˆæµ‹è¯•**ï¼ˆæ¨¡æ‹Ÿ reorgã€ç½‘ç»œæ•…éšœï¼‰

---

## æµ‹è¯•è®¡åˆ’

### å•å…ƒæµ‹è¯•

```typescript
describe('SyncStatusRepository', () => {
  it('should not advance next_block if gap exists', async () => {
    await syncRepo.advanceNextBlock(1n, 100n, 110n);
    await syncRepo.advanceNextBlock(1n, 111n, 120n);

    // ç¼ºå°‘ 110-111
    const status = await syncRepo.getSyncStatus(1n);
    expect(status.next_block).toBe(111n); // ä¸åº”æ¨è¿›åˆ° 121
  });
});
```

### é›†æˆæµ‹è¯•

```typescript
describe('Reorg Handling', () => {
  it('should detect reorg in pending zone', async () => {
    // 1. åŒæ­¥åˆ° 1000
    await syncToBlock(1000);

    // 2. æ¨¡æ‹Ÿ reorgï¼šä¿®æ”¹ 999 çš„çˆ¶å“ˆå¸Œ
    await simulateReorg(995, newForkHash);

    // 3. ç»§ç»­åŒæ­¥
    await syncToBlock(1010);

    // 4. éªŒè¯ï¼š999-1000 åº”è¯¥è¢«å›æ»š
    const block999 = await blockRepo.findById(999n);
    expect(block999.hash).toBe(newForkHash);
  });
});
```

---

## å›æ»šè®¡åˆ’

å¦‚æœä¿®å¤å¤±è´¥ï¼Œå›æ»šæ­¥éª¤ï¼š

```bash
# 1. åœæ­¢ç´¢å¼•å™¨
pkill -f "node.*index-production"

# 2. å›æ»šæ•°æ®åº“
psql -c "DROP TABLE IF EXISTS sync_status, sync_gaps, blocks_pending;"

# 3. æ¢å¤æ—§ä»£ç 
git checkout <before-fixes-commit>

# 4. é‡æ–°ç¼–è¯‘è¿è¡Œ
npm run build
npm run start:dev
```

---

## æ€»ç»“

å½“å‰ç´¢å¼•å™¨ **ä¸èƒ½æŠ•å…¥ç”Ÿäº§**ï¼Œå¿…é¡»å…ˆä¿®å¤è¿™ 3 ä¸ª Critical é—®é¢˜ã€‚

ä¿®å¤åï¼Œä½ å°†æ‹¥æœ‰ï¼š

- âœ… **ä¸ä¼šæ¼å—** - checkpoint + gap detection
- âœ… **é‡å¯å®‰å…¨** - upsert è¯­ä¹‰
- âœ… **Reorg å¯é ** - confirmation depth æ¨¡å‹
- âœ… **å¤šé“¾æ”¯æŒ** - chain_id å­—æ®µ
- âœ… **å¯è§‚æµ‹æ€§** - sync_status, gaps è¡¨

**ç”Ÿäº§å°±ç»ªåº¦**ï¼šä»å½“å‰çš„ 95/100 â†’ ä¿®å¤åçš„ **çœŸæ­£ç”Ÿäº§çº§ 99/100**

---

**å»ºè®®**ï¼š
1. ç«‹å³åœæ­¢åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨å½“å‰ç‰ˆæœ¬
2. åœ¨æµ‹è¯•ç¯å¢ƒå®æ–½ Phase 1 ä¿®å¤
3. å……åˆ†æµ‹è¯•åå†éƒ¨ç½²åˆ°ç”Ÿäº§
4. æ·»åŠ ç›‘æ§å‘Šè­¦ï¼ˆgap æ£€æµ‹ã€reorg å‘Šè­¦ï¼‰
